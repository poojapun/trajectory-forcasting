{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Fork of data-loading-and-submission-preperation\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/apandeyucsd/fork-of-data-loading-and-submission-preperation.573cedf1-2111-4f0a-aeee-baa6ec54f856.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250512/auto/storage/goog4_request%26X-Goog-Date%3D20250512T102943Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db2ad19c7b47ecf1cdb82b16924e28c01881e527f6d7df8c53c770e3e8db98dcc63af1e2c4b80d05f82b4e797e1ef3db6387be26a5bc3284fa7795f0687f3a1c39f4b430fe4ca6be561ed04c346a8f2c6c228e06f41dde3fb7677fe7b98d344b8fdbe91d9f35982ccdacf091e92f0f9714dae3d8b8d9b21a2772ed12c573c709272200aa5c2e30cff154a41aec31bb5b5fb223c5b6dcd768b5035b07026ab350f5a4afb5b1aa5af82aa7ac510bffe64f7a3ec0451fd07c39cfc0e6db09aab9c68b55973e2a25de96c6398e35bf9b65258f343749a14b24c025071a962d0b27753d0dc6a7bec45d5fd3e3d94c4e5efcf59364f757d037c70820a7a9e3ae086f368\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "import kagglehub\n",
    "kagglehub.login()\n",
    "\n",
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "apandeyucsd_cse251b_path = kagglehub.dataset_download('apandeyucsd/cse251b')\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "train_file = np.load('/kaggle/input/cse251b/train.npz')\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "\n",
    "test_file = np.load('/kaggle/input/cse251b/test_input.npz')\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_matrix = train_data[0]\n",
    "\n",
    "for i in range(data_matrix.shape[0]):\n",
    "    xs = data_matrix[i, :, 0]\n",
    "    ys = data_matrix[i, :, 1]\n",
    "    # trim all zeros\n",
    "    xs = xs[xs != 0]\n",
    "    ys = ys[ys != 0]\n",
    "    # plot each line going from transparent to full\n",
    "    plt.plot(xs, ys)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 1. Prepare data: normalize and compute displacements\n",
    "ego_pos = train_data[:,0,:,:2].astype(np.float32)  # (N,110,2)\n",
    "# compute mean/std on input portion\n",
    "mean = ego_pos[:,:50].reshape(-1,2).mean(0)\n",
    "std  = ego_pos[:,:50].reshape(-1,2).std(0) + 1e-6\n",
    "\n",
    "print((mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "ego_norm = (ego_pos - mean) / std\n",
    "\n",
    "# 1. load raw ego‐positions (N,110,2) as np.float32\n",
    "ego_np = train_data[:, 0, :, :2].astype(np.float32)\n",
    "\n",
    "# 2. compute normalization stats on the first 50 steps\n",
    "obs_np = ego_np[:, :50]    # (N,50,2)\n",
    "mean = obs_np.reshape(-1,2).mean(0)\n",
    "std  = obs_np.reshape(-1,2).std(0) + 1e-6\n",
    "\n",
    "# 3. normalize the entire sequence\n",
    "ego_norm = (ego_np - mean) / std   # still a NumPy array\n",
    "\n",
    "# 4. split normalized into obs & future (absolute positions)\n",
    "obs_norm    = ego_norm[:, :50]     # (N,50,2)\n",
    "future_norm = ego_norm[:, 50:]     # (N,60,2)\n",
    "\n",
    "# 5. convert to torch tensors\n",
    "obs_t  = torch.from_numpy(obs_norm)    # (N,50,2), dtype=torch.float32\n",
    "fut_t  = torch.from_numpy(future_norm) # (N,60,2)\n",
    "\n",
    "# 6. build per‑step displacements as a tensor\n",
    "#    δ⁰ = future[:,0] – last_obs\n",
    "last_obs = obs_t[:, -1:].clone()            # (N,1,2)\n",
    "d0       = fut_t[:, :1] - last_obs          # (N,1,2)\n",
    "#    δ¹ = future[:,1:] – future[:,:-1]\n",
    "d_rest   = fut_t[:, 1:] - fut_t[:, :-1]     # (N,59,2)\n",
    "#    concatenate → (N,60,2)\n",
    "train_y  = torch.cat([d0, d_rest], dim=1)\n",
    "\n",
    "\n",
    "train_x = obs_t\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=120):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(max_len).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0)/d_model))\n",
    "        pe[:,0::2], pe[:,1::2] = torch.sin(pos*div), torch.cos(pos*div)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "    def forward(self, x): return x + self.pe[:,:x.size(1)].to(x.device)\n",
    "\n",
    "class TrajTransformer(nn.Module):\n",
    "    def __init__(self, d_model=32, nhead=2, enc_layers=2, dec_layers=2, dim_ff=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_lin  = nn.Linear(2, d_model)\n",
    "        self.pos_enc    = PositionalEncoding(d_model)\n",
    "        self.transformer= nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=enc_layers,\n",
    "            num_decoder_layers=dec_layers,\n",
    "            dim_feedforward=dim_ff, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out_lin    = nn.Linear(d_model, 2)\n",
    "    def forward(self, src, tgt, tgt_mask):\n",
    "        # src: (B,50,2) absolute positions\n",
    "        # tgt: (B,59,2) previous true displacements\n",
    "        src = self.pos_enc(self.input_lin(src))\n",
    "        tgt = self.pos_enc(self.input_lin(tgt))\n",
    "        out = self.transformer(src, tgt, tgt_mask=tgt_mask)\n",
    "        return self.out_lin(out)\n",
    "\n",
    "tgt_len = train_y.shape[1]\n",
    "tgt_mask = torch.triu(torch.ones(tgt_len, tgt_len)*float('-inf'),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, epochs=20, bs=16, lr=1e-4, device='cpu'):\n",
    "    model.to(device)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = ReduceLROnPlateau(opt, 'min', patience=2, factor=0.5)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # — if x,y are numpy, convert; if already tensor, use as‑is\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.from_numpy(x)\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = torch.from_numpy(y)\n",
    "\n",
    "    # now x,y are Tensors\n",
    "    ds = TensorDataset(x, y)\n",
    "    loader = DataLoader(ds, batch_size=bs, shuffle=True, num_workers=0)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        for src, disp in loader:\n",
    "            src, disp = src.to(device), disp.to(device)\n",
    "            dec_in = torch.cat([torch.zeros(src.size(0),1,2,device=device),\n",
    "                                disp[:,:-1]], dim=1)\n",
    "            pred   = model(src, dec_in, tgt_mask.to(device))\n",
    "            loss   = loss_fn(pred, disp)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            total += loss.item()\n",
    "        avg = total/len(loader)\n",
    "        sched.step(avg)\n",
    "        print(f\"Epoch {epoch:02d} — MSE: {avg:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize & train\n",
    "model = TrajTransformer()\n",
    "model = train(model, train_x, train_y, epochs=15, bs=16, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_raw):\n",
    "    model.eval()\n",
    "    # normalize\n",
    "    tnorm = (test_raw - mean) / std          # (2100,50,2)\n",
    "    src   = torch.from_numpy(tnorm).float()  # we'll take [:,:50] implicitly\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(src.size(0)):\n",
    "            s      = src[i:i+1]              # (1,50,2)\n",
    "            dec_in = torch.zeros(1,60,2)     # placeholders\n",
    "            # generate one delta at a time (or feed zeros if you did full teacher-forcing)\n",
    "            out = model(s, dec_in, tgt_mask.to(s.device))   # (1,60,2)\n",
    "            # cumulative sum → normalized future positions\n",
    "            pref = tnorm[i,-1]               # (2,)\n",
    "            fut  = torch.cumsum(out, dim=1) + pref  # (1,60,2)\n",
    "            # de-normalize\n",
    "            abs_ = fut * std + mean          # (1,60,2)\n",
    "            preds.append(abs_[0])\n",
    "    return torch.stack(preds).cpu().numpy()  # (2100,60,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(model, test_data[:,0,:,:2])\n",
    "df   = pd.DataFrame(pred.reshape(-1,2), columns=['x','y'])\n",
    "df.index.name = 'index'\n",
    "df.to_csv('transformer_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='transformer_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
